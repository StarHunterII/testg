{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9975f93b-0875-4fa1-90cf-8c766445b213",
   "metadata": {},
   "source": [
    "# Пример использования LLM Saiga/Mistral 7B, Russian Mistral-based chatbot\n",
    "Автор модели [IlyaGusev](https://huggingface.co/IlyaGusev)\n",
    "\n",
    "На базе [Mistral OpenOrca](https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed4b6a-2dce-4d43-9654-60814129b749",
   "metadata": {},
   "source": [
    "### Требования\n",
    "\n",
    "1. На проектном диске необходимо 15Gb свободного места\n",
    "2. Минимальная конфигурация вычислительных ресурсов g1.1 (1 карта GPU Vidia V100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415b1ac-80de-4b81-b869-cf09764f1e49",
   "metadata": {},
   "source": [
    "### Установим библиотеки\n",
    "\n",
    "После выполнения ячейки перезагрузите ядро (Kernel -> Reset Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999975c9-7460-4636-a59c-953e45385220",
   "metadata": {
    "cellId": "ie1cctqj7tqtix8sh7lgps",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install accelerate==0.21.0  bitsandbytes==0.40.2   peft==0.5.0   transformers==4.34.0   sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008d51e-1c77-4ac0-8835-3049214051b6",
   "metadata": {},
   "source": [
    "### Задаем путь для сохранения кешированных данных модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef67dd15-5ce9-492c-9ade-ab4c888cc05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T15:30:21.395136Z",
     "iopub.status.busy": "2024-02-07T15:30:21.394222Z",
     "iopub.status.idle": "2024-02-07T15:30:21.415208Z",
     "shell.execute_reply": "2024-02-07T15:30:21.414187Z",
     "shell.execute_reply.started": "2024-02-07T15:30:21.395094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/jupyter/datasphere/project/cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd78c5e-9dd1-4f97-8bba-5b4bd2fc800d",
   "metadata": {},
   "source": [
    "### Определяем и скачиваем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce8535c-c4d1-4204-8d2f-b51deaa19f08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T15:30:24.663371Z",
     "iopub.status.busy": "2024-02-07T15:30:24.662417Z",
     "iopub.status.idle": "2024-02-07T15:30:32.096588Z",
     "shell.execute_reply": "2024-02-07T15:30:32.095385Z",
     "shell.execute_reply.started": "2024-02-07T15:30:24.663330Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 15:30:31.159126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "DEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\n",
    "DEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.<s>system\\n\"\n",
    "\n",
    "\n",
    "def generate(model, tokenizer, prompt, generation_config):\n",
    "    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    data = {k: v.to(model.device) for k, v in data.items()}\n",
    "    output_ids = model.generate(**data, generation_config=generation_config)[0]\n",
    "    output_ids = output_ids[len(data[\"input_ids\"][0]) :]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32a5d2c",
   "metadata": {
    "cellId": "3nyhedgy2qwypo9qitzxs",
    "execution": {
     "iopub.execute_input": "2024-02-07T15:30:32.099686Z",
     "iopub.status.busy": "2024-02-07T15:30:32.098295Z",
     "iopub.status.idle": "2024-02-07T15:31:24.681297Z",
     "shell.execute_reply": "2024-02-07T15:31:24.680094Z",
     "shell.execute_reply.started": "2024-02-07T15:30:32.099647Z"
    },
    "execution_id": "f1ed7e73-dc07-4a79-b2e9-29021d2bcc1c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc230b8d8494e92b23a6102b95c5de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading adapter_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0f52f860da43868457d28b20546b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5e8e83b5e84a31b69daaf4194c5529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)er_model.safetensors:   0%|          | 0.00/54.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 1536,\n",
      "  \"no_repeat_ngram_size\": 15,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.2,\n",
      "  \"top_k\": 40,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, torch_dtype=torch.float32, device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(model, MODEL_NAME, torch_dtype=torch.float32)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "print(generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40d788b2-f909-44f8-959e-1dd16c59b5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T15:31:24.684060Z",
     "iopub.status.busy": "2024-02-07T15:31:24.683241Z",
     "iopub.status.idle": "2024-02-07T15:31:25.239902Z",
     "shell.execute_reply": "2024-02-07T15:31:25.238748Z",
     "shell.execute_reply.started": "2024-02-07T15:31:24.684007Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20724e7e-b460-450e-a8c7-533d7b27b5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T15:31:25.242778Z",
     "iopub.status.busy": "2024-02-07T15:31:25.241760Z",
     "iopub.status.idle": "2024-02-07T15:31:25.258115Z",
     "shell.execute_reply": "2024-02-07T15:31:25.256858Z",
     "shell.execute_reply.started": "2024-02-07T15:31:25.242733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_template=DEFAULT_MESSAGE_TEMPLATE,\n",
    "        system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    "        response_template=DEFAULT_RESPONSE_TEMPLATE,\n",
    "    ):\n",
    "        self.message_template = message_template\n",
    "        self.response_template = response_template\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    def add_user_message(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    def add_bot_message(self, message):\n",
    "        self.messages.append({\"role\": \"bot\", \"content\": message})\n",
    "\n",
    "    def get_prompt(self, tokenizer):\n",
    "        final_text = \"\"\n",
    "        for message in self.messages:\n",
    "            message_text = self.message_template.format(**message)\n",
    "            final_text += message_text\n",
    "        final_text += DEFAULT_RESPONSE_TEMPLATE\n",
    "        return final_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35062687-0709-49c0-8d4a-45bae3639534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T15:29:29.036183Z",
     "iopub.status.busy": "2024-02-07T15:29:29.034977Z",
     "iopub.status.idle": "2024-02-07T15:29:29.049676Z",
     "shell.execute_reply": "2024-02-07T15:29:29.048535Z",
     "shell.execute_reply.started": "2024-02-07T15:29:29.036137Z"
    },
    "tags": []
   },
   "source": [
    "### Делаем запрос к модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee75dff1",
   "metadata": {
    "cellId": "qolgcczzcnl0hi2c0m97",
    "execution": {
     "iopub.execute_input": "2024-02-07T15:31:25.261090Z",
     "iopub.status.busy": "2024-02-07T15:31:25.259827Z",
     "iopub.status.idle": "2024-02-07T15:32:47.959651Z",
     "shell.execute_reply": "2024-02-07T15:32:47.958538Z",
     "shell.execute_reply.started": "2024-02-07T15:31:25.261036Z"
    },
    "execution_id": "09337bcd-b2ae-4f69-9d47-0aae81f4c775",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>system\n",
      "Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.<s>system\n",
      "</s><s>user\n",
      "Сочини длинный рассказ, обязательно упоминая следующие объекты. Дано: Баня, водка, гармонь и лосось</s><s>bot\n",
      "Однажды в небольшом городке на берегу реки произошло что-то очень важное для жителей этого места. В этот день в городе открылась новая баня, которая стала самым главным событием для всех местных жителей.\n",
      "\n",
      "Баня была построена на берегу реки, и ее стены были выполнены из камней, которые были добыты прямо на этом месте. Огромные окна давали возможность наслаждаться красивыми видами на реку и лес, окружающий город. Внутри бани было устроено несколько комнат, где можно было отдохнуть после горячего ванны или уединиться в специальной комнате для массажа.\n",
      "\n",
      "Вот как это случилось. В один из холодных зимних дней группа друзей решила попробовать новую баню. Они пришли туда ранним утром, когда в бане еще не было никого. Вход в баню был закрыт деревянными двери, которые они открыли, и вошел внутрь.\n",
      "\n",
      "Первой же комнадой, которую они посетили, была комната для массажа. Там находился молодой массажист, который предлагал различные техники массажа. Один из друзей решил попробовать массаж, и массажист начал работать над ним.\n",
      "\n",
      "В это время остальные друзья решили попробовать ванну. Ванна была очень большая, и в ней было много воды. Вода была очень горячая, и они чувствовали себя очень уютно. После того, как они вышли из ванны, они решили попробовать пиво, которое подавал бармен.\n",
      "\n",
      "После того, как они попили пива, они решили попробовать гармонику. Гармонь была очень красивая, и она производила прекрасную музыку. Они танцевали и пели вместе, а другие гости бани тоже присоединились к ним.\n",
      "\n",
      "В это время один из друзей решил попробовать лосося, который был готов на гриле. Лосось был очень вкусным, и они все еще помнят его вкус.\n",
      "\n",
      "Вот так прошёл их первый день в новой бане. Они всегда будут помнить этот день, как один из самых важных и ярких в своей жизни.\n",
      "\n",
      "==============================\n",
      "\n",
      "<s>system\n",
      "Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.<s>system\n",
      "</s><s>user\n",
      "Почему трава зеленая?</s><s>bot\n",
      "Вопрос о цвете растений задавали многие умные люди на протяжении всей истории науки. В 1960-х годах американский биолог Ральф Букер предположил, что зеленый цвет растений может быть результатом эволюции для лучшего поглощения света.\n",
      "\n",
      "Согласно теории Букера, растения, которые имели более высокую способность поглощать свет, были более успешными в борьбе за солнечный свет, который необходим для фотосинтеза - процесса, который превращает свет в энергию, которую растения могут использовать для роста и развития.\n",
      "\n",
      "Однако, это не единственная теория. Другие исследователи предполагают, что зеленый цвет может быть результатом эволюции для лучшей визуальной коммуникации между растениями. Например, зеленый цвет может быть сигналом для насекомых, которые переносят пыльцу от одного растения к другому.\n",
      "\n",
      "Таким образом, зеленый цвет растений может быть следствием эволюции для лучшего поглощения світла или для лучшей визуальной коммуникации между растительными организмами.\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"Сочини длинный рассказ, обязательно упоминая следующие объекты. Дано: Баня, водка, гармонь и лосось\", \"Почему трава зеленая?\"]\n",
    "for inp in inputs:\n",
    "    conversation = Conversation()\n",
    "    conversation.add_user_message(inp)\n",
    "    prompt = conversation.get_prompt(tokenizer)\n",
    "\n",
    "    output = generate(model, tokenizer, prompt, generation_config)\n",
    "    print(prompt)\n",
    "    print(output)\n",
    "    print()\n",
    "    print(\"==============================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c7d13-1982-487a-9fb4-12ca14904f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "d8512373-ee04-4db5-827c-f65b7465263f",
  "notebookPath": "LLM/Gusev.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
