{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9975f93b-0875-4fa1-90cf-8c766445b213",
   "metadata": {},
   "source": [
    "# Пример использования LLM Saiga/Mistral 7B, Russian Mistral-based chatbot\n",
    "Автор модели [IlyaGusev](https://huggingface.co/IlyaGusev)\n",
    "\n",
    "На базе [Mistral OpenOrca](https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ed4b6a-2dce-4d43-9654-60814129b749",
   "metadata": {},
   "source": [
    "### Требования\n",
    "\n",
    "1. На проектном диске необходимо 15Gb свободного места\n",
    "2. Минимальная конфигурация вычислительных ресурсов g1.1 (1 карта GPU Vidia V100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9415b1ac-80de-4b81-b869-cf09764f1e49",
   "metadata": {},
   "source": [
    "### Установим библиотеки\n",
    "\n",
    "После выполнения ячейки перезагрузите ядро (Kernel -> Reset Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999975c9-7460-4636-a59c-953e45385220",
   "metadata": {
    "cellId": "ie1cctqj7tqtix8sh7lgps",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install accelerate==0.21.0  bitsandbytes==0.40.2   peft==0.5.0   transformers==4.34.0   sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b008d51e-1c77-4ac0-8835-3049214051b6",
   "metadata": {},
   "source": [
    "### Задаем путь для сохранения кешированных данных модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef67dd15-5ce9-492c-9ade-ab4c888cc05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T09:44:21.370032Z",
     "iopub.status.busy": "2024-02-08T09:44:21.369071Z",
     "iopub.status.idle": "2024-02-08T09:44:21.398385Z",
     "shell.execute_reply": "2024-02-08T09:44:21.397150Z",
     "shell.execute_reply.started": "2024-02-08T09:44:21.369995Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/jupyter/datasphere/project/cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce371d2-c84b-412a-a2a6-8c1c4b35c336",
   "metadata": {},
   "source": [
    "### Определим токен для доступа к huggingface.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3513175-9161-4bd5-9dae-2c993b741e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T09:45:00.941559Z",
     "iopub.status.busy": "2024-02-08T09:45:00.940486Z",
     "iopub.status.idle": "2024-02-08T09:45:00.985388Z",
     "shell.execute_reply": "2024-02-08T09:45:00.984064Z",
     "shell.execute_reply.started": "2024-02-08T09:45:00.941507Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "access_token = os.environ['huggingface_key']\n",
    "\n",
    "#model = AutoModel.from_pretrained(\"private/model\", token=access_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd78c5e-9dd1-4f97-8bba-5b4bd2fc800d",
   "metadata": {},
   "source": [
    "### Определяем и скачиваем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce8535c-c4d1-4204-8d2f-b51deaa19f08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T15:30:24.663371Z",
     "iopub.status.busy": "2024-02-07T15:30:24.662417Z",
     "iopub.status.idle": "2024-02-08T09:47:14.660115Z",
     "shell.execute_reply": "2024-02-08T09:47:14.658925Z",
     "shell.execute_reply.started": "2024-02-08T09:46:44.267144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-08 09:47:10.204859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "DEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\n",
    "DEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.<s>system\\n\"\n",
    "\n",
    "\n",
    "def generate(model, tokenizer, prompt, generation_config):\n",
    "    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    data = {k: v.to(model.device) for k, v in data.items()}\n",
    "    output_ids = model.generate(**data, generation_config=generation_config)[0]\n",
    "    output_ids = output_ids[len(data[\"input_ids\"][0]) :]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e32a5d2c",
   "metadata": {
    "cellId": "3nyhedgy2qwypo9qitzxs",
    "execution": {
     "iopub.execute_input": "2024-02-08T09:47:36.070717Z",
     "iopub.status.busy": "2024-02-08T09:47:36.069739Z",
     "iopub.status.idle": "2024-02-08T09:56:05.778047Z",
     "shell.execute_reply": "2024-02-08T09:56:05.776721Z",
     "shell.execute_reply.started": "2024-02-08T09:47:36.070681Z"
    },
    "execution_id": "f1ed7e73-dc07-4a79-b2e9-29021d2bcc1c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384ea6486b4041b8b4b59c0ac713a960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading adapter_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7b7ecd4bd34f0892e3d88a10dc4c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ef5e32dd48440ea35687ed6448ab76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)er_model.safetensors:   0%|          | 0.00/54.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 1536,\n",
      "  \"no_repeat_ngram_size\": 15,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.2,\n",
      "  \"top_k\": 40,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(MODEL_NAME, token=access_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, torch_dtype=torch.float32, device_map=\"auto\", token=access_token)\n",
    "model = PeftModel.from_pretrained(model, MODEL_NAME, torch_dtype=torch.float32, token=access_token)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, token=access_token)\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME, token=access_token)\n",
    "print(generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d788b2-f909-44f8-959e-1dd16c59b5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T10:02:45.132103Z",
     "iopub.status.busy": "2024-02-08T10:02:45.131295Z",
     "iopub.status.idle": "2024-02-08T10:02:47.429582Z",
     "shell.execute_reply": "2024-02-08T10:02:47.428521Z",
     "shell.execute_reply.started": "2024-02-08T10:02:45.132067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20724e7e-b460-450e-a8c7-533d7b27b5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T10:02:47.432221Z",
     "iopub.status.busy": "2024-02-08T10:02:47.431238Z",
     "iopub.status.idle": "2024-02-08T10:02:47.478620Z",
     "shell.execute_reply": "2024-02-08T10:02:47.477566Z",
     "shell.execute_reply.started": "2024-02-08T10:02:47.432171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_template=DEFAULT_MESSAGE_TEMPLATE,\n",
    "        system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    "        response_template=DEFAULT_RESPONSE_TEMPLATE,\n",
    "    ):\n",
    "        self.message_template = message_template\n",
    "        self.response_template = response_template\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    def add_user_message(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    def add_bot_message(self, message):\n",
    "        self.messages.append({\"role\": \"bot\", \"content\": message})\n",
    "\n",
    "    def get_prompt(self, tokenizer):\n",
    "        final_text = \"\"\n",
    "        for message in self.messages:\n",
    "            message_text = self.message_template.format(**message)\n",
    "            final_text += message_text\n",
    "        final_text += DEFAULT_RESPONSE_TEMPLATE\n",
    "        return final_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35062687-0709-49c0-8d4a-45bae3639534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-07T15:29:29.036183Z",
     "iopub.status.busy": "2024-02-07T15:29:29.034977Z",
     "iopub.status.idle": "2024-02-07T15:29:29.049676Z",
     "shell.execute_reply": "2024-02-07T15:29:29.048535Z",
     "shell.execute_reply.started": "2024-02-07T15:29:29.036137Z"
    },
    "tags": []
   },
   "source": [
    "### Делаем запрос к модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee75dff1",
   "metadata": {
    "cellId": "qolgcczzcnl0hi2c0m97",
    "execution": {
     "iopub.execute_input": "2024-02-08T10:02:52.517844Z",
     "iopub.status.busy": "2024-02-08T10:02:52.517013Z",
     "iopub.status.idle": "2024-02-08T10:04:33.448976Z",
     "shell.execute_reply": "2024-02-08T10:04:33.447829Z",
     "shell.execute_reply.started": "2024-02-08T10:02:52.517809Z"
    },
    "execution_id": "09337bcd-b2ae-4f69-9d47-0aae81f4c775",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>system\n",
      "Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.<s>system\n",
      "</s><s>user\n",
      "Сочини длинный рассказ, обязательно упоминая следующие объекты. Дано: Баня, водка, гармонь и лосось</s><s>bot\n",
      "Однажды в маленьком городке на берегу реки жили четверо друзей - Иван, Петр, Семён и Василий. Они были неразлучными друзьями с детства и никогда не покидали друг друга. В свободное время они любили проводить время вместе, играть музыку, рыбачить и отдыхать в бане.\n",
      "\n",
      "Однажды вечером, когда все остальные жители города собрались на праздник, Иван, Петр, Семён и Василий решили провести время вместе. Они решили посетить свою любимую баню, где можно было отдохнуть после долгих рабочих дней и забыть о своих проблемах.\n",
      "\n",
      "Когда они пришли в баню, они обнаружили, что там уже много других людей. Но это не сказалось на их настроении, так как они все равно хотели провести время вместе. Они заплатили за место и начали готовиться к отдыху.\n",
      "\n",
      "Вот тут же появился местный бармен, который предложил им выпить водку. Иван, Петр, Семён и Василий не могли отказаться и попросили еще одну стаканчик. Водка была очень крепкой, но это не мешало им наслаждаться отдыхом.\n",
      "\n",
      "После того, как они отдохнули в бане, они решили продолжить веселье и поиграть на гармони. Иван был самым лучшим игроком на гармони из всех четверых друзей, и он начал играть для них песню, которая называлась \"Лосось\".\n",
      "\n",
      "Песня была очень красивой и мелодичной, и она звучала на фоне шума бани и разговоров других посетителей. Все остальные люди в бане смотрели на Ивана и его друзей и слышали песню, которая напоминала им о прекрасном мире рыбаков и их любимых лососях.\n",
      "\n",
      "Иван, Петр, Семён и Василий провели в бане весь вечер, отдыхая, питаясь и наслаждаясь компанией друзей. Они понимали, что их дружба - это то, что связывает их между собой и делает их жизнь полной.\n",
      "\n",
      "На следующий день, когда они вернулись домой, они все ещё чувствовали себя наполненными энергией и радостью от того, что они провели вместе. Они понимали, что их дружба - это не только источник счастья, но и сила, которая помогает им преодолевать трудности и наслаждаться жизнью.\n",
      "\n",
      "Иван, Петр, Семён и Василия всегда будут помнить о том вечер, когда они провели время вместе в бане, пили водку, играли на гармони и слушали песню \"Лосось\". Этот вечер стал символом их дружбы и их способности находить радость в простых вещах жизни.\n",
      "\n",
      "==============================\n",
      "\n",
      "<s>system\n",
      "Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.<s>system\n",
      "</s><s>user\n",
      "Почему трава зеленая?</s><s>bot\n",
      "Зеленый цвет у растений обусловлен наличием в них хлорофилла - пигмента, который участвует в процессе фотосинтеза. Фотосинтез - это процесс, благодаря которому растения получают энергию из света и углекислого газа, превращая их в органическое вещество (сахара и другие соединения). Хлорофилл поглощает световые волны длиной 430-450 нм (синий цвет) и 670-680 нм (красный цвет), что является основным источником энергии для фотосинтеза.\n",
      "\n",
      "Хлорофилл имеет структуру, состоящую из двух молекул виноградного спирта, одной молекулы формиамина и одной молекулы пирола. Эти компоненты образуют циклическую структуру, которая позволяет хлорофилу поглощать свет. Внутри этого цикла находится нитрогруппа, которая отвечает за поглощение красных и синих лучей.\n",
      "\n",
      "В результате фотосинтеза растения получают энергию, которую они используют для роста, развития и регуляции биологических процессов. Зеленый цвет также играет важную роль в привлечении насекомых к цветках для опыления.\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"Сочини длинный рассказ, обязательно упоминая следующие объекты. Дано: Баня, водка, гармонь и лосось\", \"Почему трава зеленая?\"]\n",
    "for inp in inputs:\n",
    "    conversation = Conversation()\n",
    "    conversation.add_user_message(inp)\n",
    "    prompt = conversation.get_prompt(tokenizer)\n",
    "\n",
    "    output = generate(model, tokenizer, prompt, generation_config)\n",
    "    print(prompt)\n",
    "    print(output)\n",
    "    print()\n",
    "    print(\"==============================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787e4b5-8011-4c78-867f-9c137ab25f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "d8512373-ee04-4db5-827c-f65b7465263f",
  "notebookPath": "LLM/Gusev.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
